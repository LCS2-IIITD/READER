{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7cb39f-ab23-4993-987a-cc1f417c26cf",
   "metadata": {},
   "source": [
    "0.18528336142008164### EXTRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d07a5e9-b560-43be-985c-90f5f4143949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "import pickle\n",
    "import pandas as pd\n",
    "file = open(\"generations\",'rb')\n",
    "gen = pickle.load(file)\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "len(gen)\n",
    "file1 = open('hope_test.txt', 'r')\n",
    "Lines = file1.readlines()\n",
    "test_list = []\n",
    "for _, line in enumerate(Lines):\n",
    "    test_list.append(line.strip())\n",
    "    \n",
    "gen_new = []\n",
    "for i in gen:\n",
    "    words = i.split(\"_eou_\")\n",
    "    # print(words)\n",
    "    # gen_new.append(\" \".join(words[0:]))\n",
    "    # print(words)\n",
    "    if len(words) < 2:\n",
    "        gen_new.append(words[0])\n",
    "    else:\n",
    "        t = \"i asdf  an e amk eo i wero niwe waon oaoe ne nein oin: \" + \" \".join(words[0:])\n",
    "        gen_new.append(\" \".join(t.split(\" \")))\n",
    "test_list_new = []\n",
    "for i in test_list:\n",
    "    words = i.split(\"_eou_\")\n",
    "    test_list_new.append(\" \".join(words[-1].split(\" \")))\n",
    "r = pd.DataFrame()\n",
    "r[\"Response\"] = gen_new[:-1]\n",
    "r[\"Targets\"] = test_list_new[1:]\n",
    "r[1:].to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70bbb572-d145-4687-8877-aa98e6159c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Output:  so what did you learn from all that? ...</td>\n",
       "      <td>It just got easier. At the beginning. It was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Output:  feel like my stats were much higher t...</td>\n",
       "      <td>habituation, habituation, right? Yeah. The fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Output:  down, right? We're just not built to ...</td>\n",
       "      <td>I noticed that before doing the exposures, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Output:  I was really, really anxious. And the...</td>\n",
       "      <td>Right. Did that change by so yesterday?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Output:  kind of went down, like the anticipat...</td>\n",
       "      <td>Yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>Output:  tomorrow, but I know what's gonna get...</td>\n",
       "      <td>it's really important because I Can't be cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>Output:  get that done. It's important to know...</td>\n",
       "      <td>by Jason, I'd like you to continue seeing a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>Output:    by Jason, I'd like you to continue ...</td>\n",
       "      <td>The Counselor has been okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>Output:  to continue seeing a counselor here. ...</td>\n",
       "      <td>But that okay, it's been okay. But we'll cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>Output:  hope that can can help you a bit. I a...</td>\n",
       "      <td>Thank you.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2174 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Response  \\\n",
       "0     Output:  so what did you learn from all that? ...   \n",
       "1     Output:  feel like my stats were much higher t...   \n",
       "2     Output:  down, right? We're just not built to ...   \n",
       "3     Output:  I was really, really anxious. And the...   \n",
       "4     Output:  kind of went down, like the anticipat...   \n",
       "...                                                 ...   \n",
       "2169  Output:  tomorrow, but I know what's gonna get...   \n",
       "2170  Output:  get that done. It's important to know...   \n",
       "2171  Output:    by Jason, I'd like you to continue ...   \n",
       "2172  Output:  to continue seeing a counselor here. ...   \n",
       "2173  Output:  hope that can can help you a bit. I a...   \n",
       "\n",
       "                                                Targets  \n",
       "0      It just got easier. At the beginning. It was ...  \n",
       "1      habituation, habituation, right? Yeah. The fa...  \n",
       "2      I noticed that before doing the exposures, I ...  \n",
       "3               Right. Did that change by so yesterday?  \n",
       "4                                                 Yeah.  \n",
       "...                                                 ...  \n",
       "2169   it's really important because I Can't be cont...  \n",
       "2170   by Jason, I'd like you to continue seeing a c...  \n",
       "2171                       The Counselor has been okay.  \n",
       "2172   But that okay, it's been okay. But we'll cont...  \n",
       "2173                                         Thank you.  \n",
       "\n",
       "[2174 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0655c-e234-4c7f-aea2-2f840522bbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc9827b-4704-4d36-b049-c937ebf2f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import Optional, Tuple\n",
    "import transformers\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from sklearn import preprocessing\n",
    "import wandb\n",
    "torch.cuda.is_available()\n",
    "import logging\n",
    "device = torch.device(\"cpu\")\n",
    "# !pip install trl\n",
    "# import trl.gpt2\n",
    "import torch\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import trl\n",
    "from trl.gpt2 import GPT2HeadWithValueModel, respond_to_batch\n",
    "from trl.ppo import PPOTrainer\n",
    "from trl.core import build_bert_batch_from_txt\n",
    "def concat_ (a,b):\n",
    "    new = []\n",
    "    for i in range(len (a)):\n",
    "        new.append(str(a[i])+': '+str(b[i]))\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7acbfc95-c8d7-45a0-8c0f-3e5efdf568d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df= pd.read_csv('data/switchboard_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "854af5ac-1efb-41be-8052-7da259cc7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.Utterance = df[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c8b2f-d500-4c1c-864e-2a3bf0992ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.read_csv(\"train_final1.csv\")\n",
    "# df2 = pd.read_csv('data/switchboard_test.csv')\n",
    "\n",
    "# train_final = concat_(df1['DamslActTag'].to_list(),df1['Text'].to_list())\n",
    "# test_final = concat_(df2['DamslActTag'].to_list(),df2['Text'].to_list())\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "df_edited = df1\n",
    "df_edited[\"Dialogue_Act\"] = label_encoder.fit_transform(df_edited[\"Dialogue_Act\"])\n",
    "# df_edited[\"Utterance\"] = df_edited[\"Text\"]\n",
    "print(\"We are working on:\",device)\n",
    "\n",
    "print(\"======================= WandB Login ===========================\")\n",
    "LOGGING = False\n",
    "if LOGGING: wandb.init(project=\"gpt2_dac_response\")\n",
    "\n",
    "print(\"======================= Reading Data ===========================\")\n",
    "def concat_ (a,b):\n",
    "    new = []\n",
    "    for i in range(len (a)):\n",
    "        new.append(str(a[i])+': '+str(b[i]))\n",
    "    return new\n",
    "\n",
    "\n",
    "\n",
    "counter = 0\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Model, GPT2LMHeadModel, AutoModel\n",
    "\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Model, GPT2PreTrainedModel\n",
    "from transformers import top_k_top_p_filtering\n",
    "from transformers.modeling_outputs import ModelOutput\n",
    "from torch import nn\n",
    "from torch.nn import Identity\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452f7695-f4f9-41ea-bbd7-bfbc794ff05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edited = df_edited[[\"Utterance\", \"Dialogue_Act\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f595b49-97fe-4f62-b157-b800f5e50b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df_edited[[\"Utterance\", \"Dialogue_Act\"]]\n",
    "# df.to_csv(\"s_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eeb9b0f-93cb-4de3-91a9-fd3bfe996adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e250f968-8acb-4b27-a20d-6a6de19d2d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Dialogue_Act</th>\n",
       "      <th>Dialogue_Act_1</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "      <td>P</td>\n",
       "      <td>&lt;sos&gt; &gt;&gt;P: I think I want to eat healthy. &lt;eos&gt;</td>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>P</td>\n",
       "      <td>&lt;sos&gt; &gt;&gt;P: I think I want to eat healthy. _eou...</td>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "      <td>P</td>\n",
       "      <td>&lt;sos&gt; &gt;&gt;P: I think I want to eat healthy. _eou...</td>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "      <td>T</td>\n",
       "      <td>&lt;sos&gt; &gt;&gt;P: I think I want to eat healthy. _eou...</td>\n",
       "      <td>irq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "      <td>P</td>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: I want to completely cut out ...</td>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9415</th>\n",
       "      <td>9415</td>\n",
       "      <td>9415</td>\n",
       "      <td>99_40</td>\n",
       "      <td>T</td>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: And I think all last year, I ...</td>\n",
       "      <td>ynq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9416</th>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>99_41</td>\n",
       "      <td>P</td>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: Yeah, _eou_ &lt;sos&gt; &gt;&gt;P: it was...</td>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9417</th>\n",
       "      <td>9417</td>\n",
       "      <td>9417</td>\n",
       "      <td>99_42</td>\n",
       "      <td>T</td>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: it was, it was better than 10...</td>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9418</th>\n",
       "      <td>9418</td>\n",
       "      <td>9418</td>\n",
       "      <td>99_43</td>\n",
       "      <td>P</td>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: I, I think I've asked most mo...</td>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9419</th>\n",
       "      <td>9419</td>\n",
       "      <td>9419</td>\n",
       "      <td>99_44</td>\n",
       "      <td>T</td>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Well, I think if you can do s...</td>\n",
       "      <td>gt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9420 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0     ID Type  \\\n",
       "0                0           0    1_0    P   \n",
       "1                1           1    1_1    P   \n",
       "2                2           2    1_2    P   \n",
       "3                3           3    1_3    T   \n",
       "4                4           4    1_4    P   \n",
       "...            ...         ...    ...  ...   \n",
       "9415          9415        9415  99_40    T   \n",
       "9416          9416        9416  99_41    P   \n",
       "9417          9417        9417  99_42    T   \n",
       "9418          9418        9418  99_43    P   \n",
       "9419          9419        9419  99_44    T   \n",
       "\n",
       "                                              Utterance Dialogue_Act  \\\n",
       "0       <sos> >>P: I think I want to eat healthy. <eos>           id   \n",
       "1     <sos> >>P: I think I want to eat healthy. _eou...           id   \n",
       "2     <sos> >>P: I think I want to eat healthy. _eou...           id   \n",
       "3     <sos> >>P: I think I want to eat healthy. _eou...          irq   \n",
       "4     _eou_ <sos> >>P: I want to completely cut out ...           id   \n",
       "...                                                 ...          ...   \n",
       "9415  _eou_ <sos> >>P: And I think all last year, I ...          ynq   \n",
       "9416  _eou_ <sos> >>T: Yeah, _eou_ <sos> >>P: it was...           id   \n",
       "9417  _eou_ <sos> >>P: it was, it was better than 10...           id   \n",
       "9418  _eou_ <sos> >>T: I, I think I've asked most mo...           id   \n",
       "9419  _eou_ <sos> >>P: Well, I think if you can do s...           gt   \n",
       "\n",
       "     Dialogue_Act_1 Emotion  \n",
       "0               NaN     NaN  \n",
       "1               NaN     NaN  \n",
       "2               NaN     NaN  \n",
       "3               NaN     NaN  \n",
       "4               NaN     NaN  \n",
       "...             ...     ...  \n",
       "9415            NaN     NaN  \n",
       "9416            NaN     NaN  \n",
       "9417            NaN     NaN  \n",
       "9418            NaN     NaN  \n",
       "9419            NaN     NaN  \n",
       "\n",
       "[9420 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"train_final1.csv\")\n",
    "df1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5387c1f-2aec-4f86-afa5-5c134d02774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances =[] \n",
    "dacs = []\n",
    "for i in range(len(df.Utterance)):\n",
    "    str = \"\"\n",
    "    for j in range(4):\n",
    "        curr = i-3+j\n",
    "        if( j % 2 == 0):\n",
    "            str = str + \"Person1: \"\n",
    "        else:\n",
    "            str = str + \"Person2: \"\n",
    "        \n",
    "        str = str + df.Utterance[max(0, curr)]\n",
    "        str = str + \" <eos> \"\n",
    "        if( j % 2 == 0):\n",
    "            str = str + \"Person2: \"\n",
    "        else:\n",
    "            str = str + \"Person1: \"\n",
    "            \n",
    "    utterances.append(str)\n",
    "    # dacs.append(df.Dialogue_Act[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394045d0-82b7-43a2-8064-b35eeddfeaf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utterances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m df_new \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m----> 2\u001b[0m df_new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUtterance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mutterances\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'utterances' is not defined"
     ]
    }
   ],
   "source": [
    "df_new = pd.DataFrame()\n",
    "df_new[\"Utterance\"] = utterances\n",
    "# df_new[\"Dialogue_Act\"] = dacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5379d0b5-9e96-4d79-92f6-d9724e3ee07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(\"test_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb9bf4a-dd1f-4064-bb89-552ead6e9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = df.tokens[0].to(device)\n",
    "# gpt2_model_ref.load_state_dict(torch.load(\"model.pt\")) \n",
    "# query[0]\n",
    "# gpt2_tokenizer.decode(\n",
    "print(gpt2_tokenizer.decode(respond_to_batch(gpt2_model, torch.tensor([query.tolist()]).to(device), top_k=8, txt_len = 100)[0], skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5839a53-091f-4370-8d59-45d0382b0175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================= WandB Login ===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mas3eem\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/aseems/miniconda3/envs/myenv/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aseems/newTrans/AAAI_Final/outputs2/wandb/run-20221012_182728-j1squk7a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/as3eem/gpt2_dac_response/runs/j1squk7a\" target=\"_blank\">colorful-puddle-525</a></strong> to <a href=\"https://wandb.ai/as3eem/gpt2_dac_response\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df\n",
    "import sentence_transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "print(\"======================= WandB Login ===========================\")\n",
    "LOGGING = True\n",
    "if LOGGING: wandb.init(project=\"gpt2_dac_response\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e6bc73c-6fd5-4ddc-8d3d-7c579b7fc883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<sos>', eos_token='<eos>', pad_token='<pad>', eou_token='_eou_', speaker_one=\">>P:\", speaker_two=\">>T:\", truncation=True)\n",
    "model.resize_token_embeddings(len(gpt2_tokenizer))\n",
    "\n",
    "model.load_state_dict(torch.load(\"model.pt\")) \n",
    "\n",
    "model.save_pretrained(\"GPT2_base\")\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"model_20epoch.pt\")) \n",
    "\n",
    "model.save_pretrained(\"GPT2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b305ccf8-02c8-4671-931a-4542a66e501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at GPT2_base and are newly initialized: ['dac_head.l1.weight', 'dac_head.l0.bias', 'dac_head.l1.bias', 'v_head.summary.weight', 'dac_head.l0.weight', 'v_head.summary.bias', 'dac_head.l2.bias', 'dac_head.l2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at GPT2 and are newly initialized: ['dac_head.l1.weight', 'dac_head.l0.bias', 'dac_head.l1.bias', 'v_head.summary.weight', 'dac_head.l0.weight', 'v_head.summary.bias', 'dac_head.l2.bias', 'dac_head.l2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "gpt2_model.resize_token_embeddings(len(gpt2_tokenizer))\n",
    "\n",
    "gpt2_model.save_pretrained(\"GPT2_base\")\n",
    "\n",
    "gpt2_model = GPT2HeadWithValueModel.from_pretrained(\"GPT2_base\", local_files_only = True).cpu()\n",
    "gpt2_model_ref = GPT2HeadWithValueModel.from_pretrained(\"GPT2\", local_files_only = True ).cpu()\n",
    "# gpt2_model.load_state_dict(torch.load(\"model_train_checkpoint1120.pt\")) \n",
    "\n",
    "# gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2', truncation=True)\n",
    "# gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "\n",
    "gpt2_model_ref.resize_token_embeddings(len(gpt2_tokenizer))\n",
    "# gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"GPT2Tokenizer\")\n",
    "# wandb.watch(gpt2_model, log='all')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac765998-ad70-46bd-97c8-bd30005fecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2bed679-0b41-447d-857a-7c93ebdde696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1690da7-1ea0-4d3d-acba-6c4ad2bcca23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Dialogue_Act</th>\n",
       "      <th>Dialogue_Act_1</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_0</td>\n",
       "      <td>T</td>\n",
       "      <td>Okay, a great job on your homework was really ...</td>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100_1</td>\n",
       "      <td>P</td>\n",
       "      <td>It just got easier. At the beginning. It was r...</td>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100_2</td>\n",
       "      <td>T</td>\n",
       "      <td>habituation, habituation, right? Yeah. The fac...</td>\n",
       "      <td>yq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100_3</td>\n",
       "      <td>P</td>\n",
       "      <td>I noticed that before doing the exposures, I w...</td>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100_4</td>\n",
       "      <td>T</td>\n",
       "      <td>Right. Did that change by so yesterday?</td>\n",
       "      <td>yq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>97_21</td>\n",
       "      <td>P</td>\n",
       "      <td>Yeah, that would probably be helpful for him t...</td>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>97_22</td>\n",
       "      <td>T</td>\n",
       "      <td>And you'd be okay saying release for him?</td>\n",
       "      <td>yq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>97_23</td>\n",
       "      <td>P</td>\n",
       "      <td>Yes, yes.</td>\n",
       "      <td>op</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>97_24</td>\n",
       "      <td>T</td>\n",
       "      <td>So I'll get you scheduled into see a counselor...</td>\n",
       "      <td>gt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>97_25</td>\n",
       "      <td>P</td>\n",
       "      <td>It's been it's been helpful. Thank you. Prepar...</td>\n",
       "      <td>gt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2241 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Type                                          Utterance  \\\n",
       "0     100_0    T  Okay, a great job on your homework was really ...   \n",
       "1     100_1    P  It just got easier. At the beginning. It was r...   \n",
       "2     100_2    T  habituation, habituation, right? Yeah. The fac...   \n",
       "3     100_3    P  I noticed that before doing the exposures, I w...   \n",
       "4     100_4    T            Right. Did that change by so yesterday?   \n",
       "...     ...  ...                                                ...   \n",
       "2236  97_21    P  Yeah, that would probably be helpful for him t...   \n",
       "2237  97_22    T          And you'd be okay saying release for him?   \n",
       "2238  97_23    P                                          Yes, yes.   \n",
       "2239  97_24    T  So I'll get you scheduled into see a counselor...   \n",
       "2240  97_25    P  It's been it's been helpful. Thank you. Prepar...   \n",
       "\n",
       "     Dialogue_Act Dialogue_Act_1 Emotion  \n",
       "0              id            NaN     NaN  \n",
       "1              id            NaN     NaN  \n",
       "2              yq            NaN     NaN  \n",
       "3              id            NaN     NaN  \n",
       "4              yq            NaN     NaN  \n",
       "...           ...            ...     ...  \n",
       "2236           id            NaN     NaN  \n",
       "2237           yq            NaN     NaN  \n",
       "2238           op            NaN     NaN  \n",
       "2239           gt            NaN     NaN  \n",
       "2240           gt            NaN     NaN  \n",
       "\n",
       "[2241 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31961a73-619d-46d2-b63a-1fa921d79c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = \"100\"\n",
    "utterance = []\n",
    "response = []\n",
    "sent = \"\"\n",
    "for idx, row in df_test.dropna().iterrows():\n",
    "    # print(row[2])\n",
    "    curr = row[\"ID\"].split(\"_\")[0]\n",
    "    if curr != last : \n",
    "        sent = \"\"\n",
    "    sent = sent + row[\"Utterance\"] + \" _eou_\"\n",
    "    response.append(row[\"Utterance\"])\n",
    "\n",
    "    utterance.append(sent)\n",
    "    last = curr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f63e9522-7df1-4eed-8099-b11a0cec8f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "new_df[\"context\"] = utterance[:-1]\n",
    "new_df[\"response\"] = response[1:]\n",
    "new_df.to_csv(\"test_d.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "20f902c1-d240-431b-95f6-3168bfd726ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I get what you're coming from but I I really did. I thought that I had it under control. And I didn't let myself get too far gone. I didn't want to be in how do I put this little Like, I want it to be in control. And I wanted to make sure that all my friends were Okay, so I didn't let myself drink too much.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['response'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2df86e4c-2f0e-452a-bb64-db6efe6013db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So Tommy I wanted to talk to because I was on Facebook the other day and saw some pictures that are kind of concerning to me of you and some of your friends at a party and you know, you're such a good kid, like, I don't know what you're doing drinking. It's good. ruin your life _eou_I mean it was just the like a social gathering it wasn't like I was looking for it the drinks were there and I have all my friends were doing it and it was just it's it's not something that I like do okay on occasion but whenever the opportunity presents itself it it's nice to just let loose and have a little bit of fun sometimes. _eou_I Tommy there's so many consequences with drinking you know you're not even 21 yet you could get arrested. You could you know have a drunk driving accident you could you know, mess up your schoolwork you have such a bright future ahead of you. It just really really concerns me. _eou_I get what you're coming from but I I really did. I thought that I had it under control. And I didn't let myself get too far gone. I didn't want to be in how do I put this little Like, I want it to be in control. And I wanted to make sure that all my friends were Okay, so I didn't let myself drink too much. _eou_\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['context'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "446eae9b-59a4-41e6-8af4-befb4057eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ What's going on? _eou_ Well, last time I started to tell you a little bit about one of my friends, my best friend Actually, she had this issue. So what happened was she went to a bathroom at our local library, and she found a video camera when she was going to the bathroom _eou_ in the bathroom? _eou_ Yeah, she actually, yeah. And she turned it into the police. And I guess\n"
     ]
    }
   ],
   "source": [
    "keyword = i\n",
    "# print(i)\n",
    "keyword = \" \".join(keyword.split()[-50:])\n",
    "keyword = \"this \"\n",
    "# print(keyword)\n",
    "input_seq = keyword \n",
    "generated = torch.tensor(gpt2_tokenizer.encode(input_seq, return_token_type_ids=False)).unsqueeze(0)\n",
    "generated = generated.to(device)\n",
    "sample_outputs = model.generate(\n",
    "                        generated, \n",
    "                        length_penalty = -10,\n",
    "                        do_sample=False,   \n",
    "                        top_k=9, \n",
    "                        min_length = 50,\n",
    "                        max_length = 100,\n",
    "                        top_p=0.7\n",
    "                        # num_beams = 10\n",
    "                        )\n",
    "# print(\"==========================================\")\n",
    "t = (gpt2_tokenizer.decode(sample_outputs[0][len(keyword):], skip_special_tokens=False))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0962ef71-08db-4196-9fca-15df3b4056c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for i in utterance:\n",
    "    input_seq = i\n",
    "    generated = torch.tensor(gpt2_tokenizer.encode(input_seq, return_token_type_ids=False)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "    sample_outputs = model.generate(\n",
    "                            generated, \n",
    "                            length_penalty = -10,\n",
    "                            do_sample=False,   \n",
    "                            top_k=9, \n",
    "                            min_length = 50,\n",
    "                            max_length = 100,\n",
    "                            top_p=0.7\n",
    "                            # num_beams = 10\n",
    "                            )\n",
    "    # print(\"==========================================\")\n",
    "    t = (gpt2_tokenizer.decode(sample_outputs[0][len(keyword):], skip_special_tokens=False))\n",
    "    print(t)\n",
    "    # t = interactive(\" \".join(i.split()[-20:]), gpt2_tokenizer, model)\n",
    "    # print(t)\n",
    "    responses.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7db7ce-e33f-4843-8589-5530d748da70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45457660-32cb-4b70-8513-a2ac268222dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "def interactive(input, tokenizer, model, top_k=9, ntok=20):\n",
    "    \"\"\"\n",
    "    Generate and print out the response given input using the trained model\n",
    "    :param input: an input string as prompt (i.e. How are you?)\n",
    "    :param tokenizer: intialized tokenizer object for encoding the input\n",
    "    :param model: the trained model to use for generate prediction\n",
    "    :param top_k: number of samples for top_l sampling\n",
    "    :param ntok: maximum number of tokens to generate\n",
    "    Comment: Feed in the input to the model to generate the most probable\n",
    "    token and concatenate it with current input.\n",
    "    Continue this process iteratively until the model predicts the padding\n",
    "    token or reach the maximum number of tokens.\n",
    "    You may need to add the BOS token and special token to the input sentence\n",
    "    before passing into model.\n",
    "    Also, you may want to filter out your input sentence and meaningless tokens\n",
    "    when printing out the response.\n",
    "    \"\"\"\n",
    "    prompt = input\n",
    "\n",
    "    # prompt = '<b> '+ pr\n",
    "    \n",
    "    enc = torch.tensor(tokenizer.encode(prompt, add_special_tokens=True)).unsqueeze(0).cpu()\n",
    "    response = []\n",
    "\n",
    "    while len(response) < ntok:\n",
    "        with torch.no_grad():\n",
    "            logits = model(enc).logits[0]\n",
    "            # print(logits.size())\n",
    "            # print(logits.size())\n",
    "            #logits = logits.view(-1, logits.shape[1])\n",
    "            topk, inds = torch.topk(logits, k=top_k)\n",
    "            new_logits = Variable(torch.zeros(logits.size(0), logits.size(1))).cpu()\n",
    "            logits = new_logits.scatter(1, inds, topk)\n",
    "            \n",
    "            probs = F.relu(logits[-1]) + 1e-9\n",
    "            predicted = torch.multinomial(probs, 1)\n",
    "            # next_token = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
    "\n",
    "            \n",
    "            #new_word = predicted[-1].unsqueeze(0)\n",
    "            \n",
    "            if predicted.item() == tokenizer.pad_token_id:\n",
    "                break\n",
    "            else:\n",
    "                # print(enc)\n",
    "                # print(predicted)\n",
    "                enc = torch.cat((enc[0], predicted), 0).unsqueeze(0)\n",
    "                response.append(predicted.item())\n",
    "                \n",
    "    decoded = tokenizer.decode(response, skip_special_tokens=False)\n",
    "    # print(\"Response:\", decoded)\n",
    "    return decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1420daee-1a32-4571-b1b1-4de99bf94462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Dialogue_Act</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;sos&gt; &gt;&gt;P: I think I want to eat healthy. &lt;eos&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>I want to completely cut out fast food. I want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;sos&gt; &gt;&gt;P: I think I want to eat healthy. _eou...</td>\n",
       "      <td>5</td>\n",
       "      <td>I think I at least needs to go to the grocery....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;sos&gt; &gt;&gt;P: I think I want to eat healthy. _eou...</td>\n",
       "      <td>5</td>\n",
       "      <td>Is that something that you haven't been doing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;sos&gt; &gt;&gt;P: I think I want to eat healthy. _eou...</td>\n",
       "      <td>6</td>\n",
       "      <td>No, not lately. I've just been grabbing food a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: I want to completely cut out ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Like, I just haven't had the energy or desire ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9415</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: And I think all last year, I ...</td>\n",
       "      <td>10</td>\n",
       "      <td>Well, I think if you can do something for some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9416</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: Yeah, _eou_ &lt;sos&gt; &gt;&gt;P: it was...</td>\n",
       "      <td>5</td>\n",
       "      <td>right? To raise money for ALzheimer's without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9417</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: it was, it was better than 10...</td>\n",
       "      <td>5</td>\n",
       "      <td>Yeah. Wow. Yeah. Yeah, that should be good. no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9418</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: I, I think I've asked most mo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9419</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Well, I think if you can do s...</td>\n",
       "      <td>4</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9420 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance  Dialogue_Act  \\\n",
       "0       <sos> >>P: I think I want to eat healthy. <eos>             5   \n",
       "1     <sos> >>P: I think I want to eat healthy. _eou...             5   \n",
       "2     <sos> >>P: I think I want to eat healthy. _eou...             5   \n",
       "3     <sos> >>P: I think I want to eat healthy. _eou...             6   \n",
       "4     _eou_ <sos> >>P: I want to completely cut out ...             5   \n",
       "...                                                 ...           ...   \n",
       "9415  _eou_ <sos> >>P: And I think all last year, I ...            10   \n",
       "9416  _eou_ <sos> >>T: Yeah, _eou_ <sos> >>P: it was...             5   \n",
       "9417  _eou_ <sos> >>P: it was, it was better than 10...             5   \n",
       "9418  _eou_ <sos> >>T: I, I think I've asked most mo...             5   \n",
       "9419  _eou_ <sos> >>P: Well, I think if you can do s...             4   \n",
       "\n",
       "                                                 target  \n",
       "0     I want to completely cut out fast food. I want...  \n",
       "1     I think I at least needs to go to the grocery....  \n",
       "2        Is that something that you haven't been doing?  \n",
       "3     No, not lately. I've just been grabbing food a...  \n",
       "4     Like, I just haven't had the energy or desire ...  \n",
       "...                                                 ...  \n",
       "9415  Well, I think if you can do something for some...  \n",
       "9416  right? To raise money for ALzheimer's without ...  \n",
       "9417  Yeah. Wow. Yeah. Yeah, that should be good. no...  \n",
       "9418                                         Thank you.  \n",
       "9419                                                nan  \n",
       "\n",
       "[9420 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"train.csv\")\n",
    "\n",
    "df[\"target\"] = [str(x) for x in df3[\"Utterance\"][1:]]\n",
    " \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9c542c24-79bb-4557-be01-91855cc38a05",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'would', 'you', 'actually', 'give', 'it', 'in', 'the', 'end?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <sos> <eos> <sos> <eos> <sos> <sos> <eos> <eos> <sos> <eos> <sos> <eos> <eos> <sos> <eos>\n",
      "['those', 'two', 'and', 'respect,', 'respect.', '_eou_', '<sos>', '>>T:', 'Okay,', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <sos> <sos> <sos> <eos> <sos> <sos> <eos> <sos> <eos> <sos> <eos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <sos> <sos> <sos>\n",
      "['I', 'mean,', \"there's\", 'so', 'many', 'things', \"it's\", \"it's\", 'everywhere.', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <sos> <eos> <sos> <sos> <eos> <eos> <sos> <eos> <sos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
      "['_eou_', '<sos>', '>>T:', 'you', 'have', 'a', 'craving', 'for', 'marijuana', '<eos>']\n",
      "++++++++++++++++++++ <sos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <sos> <sos> <eos> <sos> <eos> <eos>\n",
      "['thinking', 'that', 'might', 'be', 'a', 'better', 'way', 'to', 'go?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <eos> <eos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos>\n",
      "['64', '_eou_', '<sos>', '>>T:', 'Okay,', 'good.', 'What', 'is', 'this?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <sos> <sos> <sos> <eos> <sos> <sos> <sos> <eos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <sos> <sos> <eos> <sos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
      "['about', 'evidence', 'that', 'refutes', 'that', \"you're\", 'not', 'good', 'enough?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <sos> <eos> <sos> <sos> <sos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos>\n",
      "['with', 'you', 'to', 'talk', 'a', 'little', 'bit', 'about', 'that,', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <sos> <eos> <eos> <eos> <sos> <eos> <eos> <sos> <sos> <eos> <eos> <eos>\n",
      "['are', 'we', 'on?', '_eou_', '<sos>', '>>P:', 'The', 'first', 'floor?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <sos> <eos> <sos> <eos> <sos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <eos>\n",
      "['very', 'good', 'at', 'staying', 'focused', 'on', 'stuff', 'like', 'that.', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <sos> <sos> <eos>\n",
      "['do.', '_eou_', '<sos>', '>>T:', 'How', 'about', 'blurting', 'things', 'out?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <sos> <eos> <eos> <sos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <sos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
      "['thought?', 'And', 'you', 'went', 'to', 'work', 'on', 'time', 'still?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <sos>\n",
      "['important', 'it', 'is', 'to', 'you', '_eou_', '<sos>', '>>P:', 'Yeah.', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos>\n",
      "['>>T:', 'this', 'specific', 'a', 'year', '_eou_', '<sos>', '>>P:', 'yeah.', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <sos>\n",
      "['it', 'was', 'my', 'idea.', '_eou_', '<sos>', '>>T:', 'Right', 'Right.', '<eos>']\n",
      "++++++++++++++++++++ <eos> <sos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <sos> <eos> <eos> <eos> <sos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <sos>\n",
      "['going', 'on', 'for', 'answering', 'my', 'questions.', \"It's\", 'been', 'helpful.', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <sos> <eos> <sos> <sos> <eos>\n",
      "['just', 'just', 'planning', 'and', 'seeing', 'how', 'it', 'would', 'look.', '<eos>']\n",
      "++++++++++++++++++++ <sos> <sos> <sos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <sos> <sos> <eos> <sos> <eos> <eos> <sos> <sos>\n",
      "['else', 'needs', 'to', 'yet', 'be', 'aware', 'of', 'that.', 'Okay.', '<eos>']\n",
      "++++++++++++++++++++ <eos> <sos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <sos>\n",
      "['sounds', 'like', 'things', 'have', 'been', 'going', 'pretty', 'well', 'recently,', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
      "['for', 'them', 'to', 'have', 'the', 'living', 'room', 'and', 'not', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <sos> <eos> <sos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <sos> <sos> <eos> <eos> <eos> <sos> <eos> <eos>\n",
      "['whole', \"thing's\", 'a', 'mess.', 'And', \"it's\", 'just', \"it's\", 'annoying.', '<eos>']\n",
      "++++++++++++++++++++ <sos> <eos> <eos> <eos> <eos> <sos> <sos> <sos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <sos>\n",
      "['people', 'too,', 'you', 'know,', 'but', 'really', \"hasn't\", 'gotten', 'anywhere.', '<eos>']\n",
      "++++++++++++++++++++ <eos> <sos> <eos> <sos> <sos> <sos> <eos> <eos> <eos> <sos> <eos> <eos> <sos> <sos> <sos> <eos>  how <eos> <eos> <eos> <sos>  about <eos> <eos> <sos> <eos> <eos> <sos> <eos> <eos>  about <eos> <eos> <eos> <sos>  I <eos> <eos> <eos> <eos>\n",
      "['you', 'choose', 'a', 'seven', 'out', 'of', 'five', 'or', 'four?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <eos> <sos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <sos>\n",
      "['So', 'how', 'has', 'this', 'week', 'been', 'back', 'at', 'work?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <sos>\n",
      "['alcohol', 'use', 'or', 'medical', 'conditions.', '_eou_', '<sos>', '>>P:', 'No', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <sos> <sos> <sos> <sos> <eos> <eos> <eos>\n",
      "['that', 'limit?', 'Or,', 'or', 'what', 'do', 'you', 'think', '?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <sos> <sos> <eos> <sos> <eos> <sos> <eos> <sos> <eos> <eos> <eos> <eos>\n",
      "['<sos>', '>>P:', 'Im', 'here', '_eou_', '<sos>', '>>T:', \"you're\", 'good?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <sos> <eos> <eos> <eos> <sos> <eos> <eos>\n",
      "['and', 'then', 'you', 'lose,', 'you', 'know,', 'at', 'the', 'end.', '<eos>']\n",
      "++++++++++++++++++++ <eos> <sos> <eos> <sos> <eos> <sos> <sos> <sos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <sos> <eos> <eos> <eos> <sos> <sos> <eos> <eos> <eos> <sos>\n",
      "['anything.', \"They're\", 'not', 'listening', 'to', 'me', 'about', 'my', 'feelings.', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <sos> <eos> <eos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
      "['ago', 'was', 'it', 'that', 'you', 'moved', 'to', 'the', 'florida?', '<eos>']\n",
      "++++++++++++++++++++ <eos> <eos> <sos> <sos> <sos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n"
     ]
    }
   ],
   "source": [
    "df_batch = df.sample(30)\n",
    "inputs = df_batch.Utterance.tolist()\n",
    "target = df_batch.target.tolist()\n",
    "dac = df_batch.target.tolist()\n",
    "\n",
    "for i in inputs:\n",
    "    print(i.split()[-10:])\n",
    "    out = interactive(\" \".join(i.split()[-10:]), gpt2_tokenizer, gpt2_model, top_k = 5)\n",
    "    print(\"++\"*10, out)\n",
    "    outputs.append(out)\n",
    "# sent = \"_eou_ <sos> >>T: Exciting ? _eou_ <sos> >>P: Yeah, it definitely is. I can do that. _eou_ <sos> >>T: So I will see you and next week ? _eou_ <sos> >>P: okay <eos>',\"\n",
    "# interactive(sent+sent+sent + sent, gpt2_tokenizer, gpt2_model, top_k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da7afd9f-c333-42bf-8ffb-120c3aa0065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gpt2_model\n",
    "tokenizer = gpt2_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e46b9423-7bf9-4784-913b-80aa1f44cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch.to_csv(\"n.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9df4ecb6-b880-4a56-a10b-354085820a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_keywords(keywords):\n",
    "    outputs=[]\n",
    "    model.eval()\n",
    "    for keyword in tqdm(keywords):\n",
    "        keyword = \" \".join(keyword.split()[-20:])\n",
    "        input_seq = \"<sos> \" + keyword + \" _eou_ \"\n",
    "        generated = torch.tensor(tokenizer.encode(input_seq, return_token_type_ids=False)).unsqueeze(0)\n",
    "        generated = generated.to(device)\n",
    "        # sample_outputs = model.generate(\n",
    "        #                             generated, \n",
    "        #                             do_sample=True,   \n",
    "        #                             top_k=30, \n",
    "        #                             max_length = 50,\n",
    "        #                             top_p=0.90, \n",
    "        #                             num_return_sequences=2\n",
    "        #                             )\n",
    "        sample_outputs = model.generate(\n",
    "                                    generated, \n",
    "                                    min_length= 20,\n",
    "                                    max_length = 80,\n",
    "                                    )\n",
    "        # print(\"\\n\\n ====== \\n\")\n",
    "        # print(input_seq)\n",
    "        # print(\"\\n -- -- \\n\")\n",
    "\n",
    "        # print(sample_outputs)\n",
    "        # print(\"--- ---\")\n",
    "        # print(sample_outputs[0])\n",
    "        # print(\"--- ---\")\n",
    "\n",
    "        # print(tokenizer.decode(sample_outputs[0], skip_special_tokens=True))\n",
    "        # print(tokenizer.decode(sample_outputs[1], skip_special_tokens=True))\n",
    "        \n",
    "        outputs.append(tokenizer.decode(sample_outputs[0], skip_special_tokens=True))        \n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40e07cb3-7fdc-488f-b9d9-a0df202c3052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                     | 0/30 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  3%|█████▊                                                                                                                                                                       | 1/30 [00:01<00:47,  1.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  7%|███████████▌                                                                                                                                                                 | 2/30 [00:02<00:35,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 10%|█████████████████▎                                                                                                                                                           | 3/30 [00:03<00:35,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 13%|███████████████████████                                                                                                                                                      | 4/30 [00:05<00:35,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 17%|████████████████████████████▊                                                                                                                                                | 5/30 [00:06<00:35,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 20%|██████████████████████████████████▌                                                                                                                                          | 6/30 [00:08<00:31,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 23%|████████████████████████████████████████▎                                                                                                                                    | 7/30 [00:09<00:31,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 27%|██████████████████████████████████████████████▏                                                                                                                              | 8/30 [00:11<00:32,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 30%|███████████████████████████████████████████████████▉                                                                                                                         | 9/30 [00:12<00:27,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 33%|█████████████████████████████████████████████████████████▎                                                                                                                  | 10/30 [00:13<00:28,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 37%|███████████████████████████████████████████████████████████████                                                                                                             | 11/30 [00:15<00:25,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 40%|████████████████████████████████████████████████████████████████████▊                                                                                                       | 12/30 [00:16<00:25,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 43%|██████████████████████████████████████████████████████████████████████████▌                                                                                                 | 13/30 [00:17<00:22,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 47%|████████████████████████████████████████████████████████████████████████████████▎                                                                                           | 14/30 [00:19<00:21,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████████████                                                                                      | 15/30 [00:20<00:20,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 53%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                | 16/30 [00:22<00:20,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 57%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                          | 17/30 [00:23<00:19,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 18/30 [00:25<00:18,  1.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 63%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 19/30 [00:27<00:17,  1.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 20/30 [00:28<00:16,  1.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 21/30 [00:30<00:14,  1.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 22/30 [00:31<00:12,  1.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                        | 23/30 [00:33<00:10,  1.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 24/30 [00:34<00:08,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 25/30 [00:35<00:06,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 26/30 [00:37<00:05,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 27/30 [00:38<00:04,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 28/30 [00:40<00:02,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 29/30 [00:41<00:01,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "new = eval_keywords(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b28aadd-08ee-464d-8dc4-330b31dad749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = pd.read_csv(\"new.csv\")\n",
    "# df_b = df_b[[\"target\",\"predicted_rac\",\"\"]]\n",
    "predicted = df_b.predicted_rac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39173199-e58c-45ab-9ad6-bfa081c2b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "22744d92-6b83-49d4-9ec2-80f81c538142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = pd.DataFrame()\n",
    "df_fin[\"Utterance\"] = inputs[:-1]\n",
    "df_fin[\"Generated\"] = new[:-1]\n",
    "df_fin[\"Target\"] = target[:-1]\n",
    "# df_fin[\"dac_next\"] = df_batch.reset_index(drop=True).Dialogue_Act.tolist()[1:]\n",
    "# df_fin[\"predicted_rac\"] = predicted\n",
    "df_fin.to_csv(\"ne2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97b5291b-ef0b-4e30-9f08-98a3739ac630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Generated</th>\n",
       "      <th>Target</th>\n",
       "      <th>dac_next</th>\n",
       "      <th>predicted_rac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: walk off, okay or he will  be...</td>\n",
       "      <td>in your life that you can talk to. What do yo...</td>\n",
       "      <td>And I think also, he understood why I did it. ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;sos&gt; &gt;&gt;T: So Steph, I know you just want to g...</td>\n",
       "      <td>&gt;&gt;T: Hello, Peggy, how you doing today? _eou...</td>\n",
       "      <td>I don't really feel like filling out a plan. I...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: Yeah. any substance related p...</td>\n",
       "      <td>change and it's very important to you that yo...</td>\n",
       "      <td>Okay. And we'll talk about any type of legal p...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Well, alcohol definitely impa...</td>\n",
       "      <td>&gt;&gt;T: Jasmine how you doing today? _eou_  &gt;&gt;P...</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Yeah, I have some pills in my...</td>\n",
       "      <td>versus just not just a friend's house like an...</td>\n",
       "      <td>Um, you know, I want to make sure that all the...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: Do you feel the trick good in...</td>\n",
       "      <td>back. _eou_  &gt;&gt;T: So you weren't you weren't ...</td>\n",
       "      <td>How would you describe your mood? Most of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: And how much do you believe t...</td>\n",
       "      <td>went anyway. _eou_  &gt;&gt;T: So was it after he h...</td>\n",
       "      <td>And you believe them now. Right? So try to kee...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: It wasn't that long. She was ...</td>\n",
       "      <td>late, but I'm late enough. _eou_  &gt;&gt;T: Have y...</td>\n",
       "      <td>No, I just stopped going</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Yes, I do. Yeah. Yeah. Well, ...</td>\n",
       "      <td>&gt;&gt;T: But eventually you're going to come to o...</td>\n",
       "      <td>And then I'm Facebook friends when they go hom...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;sos&gt; &gt;&gt;T: between here and there, obviously, ...</td>\n",
       "      <td>around. _eou_  &gt;&gt;T: So mainly just kind of ha...</td>\n",
       "      <td>What are you gonna do if I fail?</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Yes, it is.  _eou_ &lt;sos&gt; &gt;&gt;T:...</td>\n",
       "      <td>hallway? _eou_  &gt;&gt;P: Just different things. _...</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Yeah, I'm gonna have to get a...</td>\n",
       "      <td>I can see how distressed This makes you feel....</td>\n",
       "      <td>long time ago, I've been using proudly for Sin...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: So you're worried about distu...</td>\n",
       "      <td>dad is Steve. They actually got divorced when...</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: distress, right? Well, acute,...</td>\n",
       "      <td>I don't like I feel back. It might be hard, l...</td>\n",
       "      <td>And how many days and the average week are you...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Well, you know, I'm always ge...</td>\n",
       "      <td>No, I mean, I don't want my son, If he ever f...</td>\n",
       "      <td>Yeah. You know, like, sometimes people just, i...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Well I don't think they will ...</td>\n",
       "      <td>if this had happened to. Have you ever been i...</td>\n",
       "      <td>Well, actually, for this semester, I already t...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: you're successful in getting ...</td>\n",
       "      <td>like that. _eou_  &gt;&gt;T: And when you and your ...</td>\n",
       "      <td>Being able to travel.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Yeah. I haven't been able to ...</td>\n",
       "      <td>She's upset about that. _eou_  &gt;&gt;P: Yeah, yea...</td>\n",
       "      <td>Have you noticed a change in your ability to e...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: how about Your work are you h...</td>\n",
       "      <td>I just did it myself, _eou_  &gt;&gt;T: does it fru...</td>\n",
       "      <td>you have some social problems. Not so much wit...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Yeah, yeah. _eou_ &lt;sos&gt; &gt;&gt;T: ...</td>\n",
       "      <td>want to hurt anyone. I feel like I've got to ...</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: so no, no, never. I I would n...</td>\n",
       "      <td>you want to discuss? Or I mean, would you lik...</td>\n",
       "      <td>I'd hope he'd say yes.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: Kinda Okay, well as we've tal...</td>\n",
       "      <td>I'm wondering if part of the difficulty you'r...</td>\n",
       "      <td>Okay, so it sounds like you're saying then it'...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: Chances are, I'm going to get...</td>\n",
       "      <td>same time when those thoughts come up to resp...</td>\n",
       "      <td>So I like that adaptive response. Right. Do yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: double checking, for example,...</td>\n",
       "      <td>when I try and sleep I just can't seem to hav...</td>\n",
       "      <td>So what do you think the solution here is your...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: So I don't think that there i...</td>\n",
       "      <td>nervous on edge, anything? _eou_  &gt;&gt;P: Well, ...</td>\n",
       "      <td>Okay, well, perhaps it would be helpful to sor...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Um, whenever I drink too much...</td>\n",
       "      <td>be able to take care of them, even if you're ...</td>\n",
       "      <td>Wow, I would say probably</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: I don't know exactly, because...</td>\n",
       "      <td>&gt;&gt;T: Jasmine how you doing today?  _eou_  An...</td>\n",
       "      <td>Not like this. Now is the first time I've just...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: Look, I can understand why yo...</td>\n",
       "      <td>the doctor that you're going to see. Let's ju...</td>\n",
       "      <td>so tell me how it helps you.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: yeah. _eou_ &lt;sos&gt; &gt;&gt;T: How ca...</td>\n",
       "      <td>_eou_  &gt;&gt;T: Okay, so would it work if I was m...</td>\n",
       "      <td>Yeah, I think yes.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Yes, because I might trust yo...</td>\n",
       "      <td>the service of _eou_  &gt;&gt;P: the Advanced Study...</td>\n",
       "      <td>Correct. Without my room, and without the tech...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: looks really bad. Um, is ther...</td>\n",
       "      <td>don't know. I don't know if there is what was...</td>\n",
       "      <td>Um, is there anything else?</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: I don't think you will either...</td>\n",
       "      <td>got it all that felt so good get it up so the...</td>\n",
       "      <td>Oh, so you are on the water pill? The furosemi...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: So about a year ago, you went...</td>\n",
       "      <td>and they end up leaving anyway. _eou_  &gt;&gt;T: R...</td>\n",
       "      <td>your physicians, physicians run tests for all ...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Yeah. _eou_ &lt;sos&gt; &gt;&gt;T: How of...</td>\n",
       "      <td>Okay, _eou_  &gt;&gt;P: yes. _eou_  &gt;&gt;T: And. Okay,...</td>\n",
       "      <td>Um, I mean, I have I've had a few boyfriends b...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: Can you see yourself being ab...</td>\n",
       "      <td>you easily distracted? _eou_  &gt;&gt;P: Yes. Take ...</td>\n",
       "      <td>A lot of the corsage to some of the effectiven...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: well a couple of years ago wh...</td>\n",
       "      <td>But some of those were half days. They add up...</td>\n",
       "      <td>Yeah. In situation.</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Yeah, well, I was referred to...</td>\n",
       "      <td>you're reacting to the quizzes maybe. _eou_  ...</td>\n",
       "      <td>Yeah. Oh, It has crept up over the years. Well...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: So over the course of the day...</td>\n",
       "      <td>contributing to the way that he's behaving to...</td>\n",
       "      <td>right. So is it mainly vodka</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: Okay, are your mom dad and si...</td>\n",
       "      <td>maybe to 16 when you were more active. involv...</td>\n",
       "      <td>So Victor, tell me, how's your sleep? And what...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: You should be proactive in wa...</td>\n",
       "      <td>_eou_  &gt;&gt;T: Okay. Okay, but you've not wanted...</td>\n",
       "      <td>Yeah, maybe I just need to let him know that A...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Yes, he is. Yeah.  _eou_ &lt;sos...</td>\n",
       "      <td>ultimately a judge can order me and I have to...</td>\n",
       "      <td>Well, it's the same thing that I see Dr. Jones...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: Alrigh. No pun intended, righ...</td>\n",
       "      <td>through a possible scenario. And what this co...</td>\n",
       "      <td>And we want you to be able to, you know, genui...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>&lt;sos&gt; &gt;&gt;T: Hi Sandra. How are you doing today....</td>\n",
       "      <td>&gt;&gt;P: I am 20. _eou_  &gt;&gt;T: You're 20 Okay, whe...</td>\n",
       "      <td>I'm going to ask you some questions and give y...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: are you going to? _eou_ &lt;sos&gt;...</td>\n",
       "      <td>Yes. Safety. Definitely my personal safety or...</td>\n",
       "      <td>Before for bed?</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Yeah _eou_ &lt;sos&gt; &gt;&gt;T: okay. O...</td>\n",
       "      <td>_eou_  &gt;&gt;P: Yeah. drugs, alcohol. Yeah, I'd r...</td>\n",
       "      <td>yes, And at the same time, I had a barium enem...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: And you're having what sounds...</td>\n",
       "      <td>&gt;&gt;T: Um, is there anything else? _eou_  &gt;&gt;P:...</td>\n",
       "      <td>you are. So no one's really seeing you have th...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;T: So that was one issue. Now if...</td>\n",
       "      <td>good enough and on the other way and it's not...</td>\n",
       "      <td>okay hundred percent ?</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Okay,  _eou_ &lt;sos&gt; &gt;&gt;T: so le...</td>\n",
       "      <td>encounter, and that's where you're getting th...</td>\n",
       "      <td>Oh yeah,</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>_eou_ &lt;sos&gt; &gt;&gt;P: Sure, my left elbow is actual...</td>\n",
       "      <td>_eou_  &gt;&gt;P: Yeah, just this feeling of failur...</td>\n",
       "      <td>Um, it's just kind of a throbbing pain, it'll ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Utterance  \\\n",
       "0   _eou_ <sos> >>P: walk off, okay or he will  be...   \n",
       "1   <sos> >>T: So Steph, I know you just want to g...   \n",
       "2   _eou_ <sos> >>T: Yeah. any substance related p...   \n",
       "3   _eou_ <sos> >>P: Well, alcohol definitely impa...   \n",
       "4   _eou_ <sos> >>P: Yeah, I have some pills in my...   \n",
       "5   _eou_ <sos> >>T: Do you feel the trick good in...   \n",
       "6   _eou_ <sos> >>T: And how much do you believe t...   \n",
       "7   _eou_ <sos> >>P: It wasn't that long. She was ...   \n",
       "8   _eou_ <sos> >>P: Yes, I do. Yeah. Yeah. Well, ...   \n",
       "9   <sos> >>T: between here and there, obviously, ...   \n",
       "10  _eou_ <sos> >>P: Yes, it is.  _eou_ <sos> >>T:...   \n",
       "11  _eou_ <sos> >>P: Yeah, I'm gonna have to get a...   \n",
       "12  _eou_ <sos> >>T: So you're worried about distu...   \n",
       "13  _eou_ <sos> >>T: distress, right? Well, acute,...   \n",
       "14  _eou_ <sos> >>P: Well, you know, I'm always ge...   \n",
       "15  _eou_ <sos> >>P: Well I don't think they will ...   \n",
       "16  _eou_ <sos> >>T: you're successful in getting ...   \n",
       "17  _eou_ <sos> >>P: Yeah. I haven't been able to ...   \n",
       "18  _eou_ <sos> >>T: how about Your work are you h...   \n",
       "19  _eou_ <sos> >>P: Yeah, yeah. _eou_ <sos> >>T: ...   \n",
       "20  _eou_ <sos> >>P: so no, no, never. I I would n...   \n",
       "21  _eou_ <sos> >>T: Kinda Okay, well as we've tal...   \n",
       "22  _eou_ <sos> >>T: Chances are, I'm going to get...   \n",
       "23  _eou_ <sos> >>T: double checking, for example,...   \n",
       "24  _eou_ <sos> >>T: So I don't think that there i...   \n",
       "25  _eou_ <sos> >>P: Um, whenever I drink too much...   \n",
       "26  _eou_ <sos> >>P: I don't know exactly, because...   \n",
       "27  _eou_ <sos> >>T: Look, I can understand why yo...   \n",
       "28  _eou_ <sos> >>P: yeah. _eou_ <sos> >>T: How ca...   \n",
       "29  _eou_ <sos> >>P: Yes, because I might trust yo...   \n",
       "30  _eou_ <sos> >>T: looks really bad. Um, is ther...   \n",
       "31  _eou_ <sos> >>T: I don't think you will either...   \n",
       "32  _eou_ <sos> >>T: So about a year ago, you went...   \n",
       "33  _eou_ <sos> >>P: Yeah. _eou_ <sos> >>T: How of...   \n",
       "34  _eou_ <sos> >>T: Can you see yourself being ab...   \n",
       "35  _eou_ <sos> >>P: well a couple of years ago wh...   \n",
       "36  _eou_ <sos> >>P: Yeah, well, I was referred to...   \n",
       "37  _eou_ <sos> >>T: So over the course of the day...   \n",
       "38  _eou_ <sos> >>T: Okay, are your mom dad and si...   \n",
       "39  _eou_ <sos> >>P: You should be proactive in wa...   \n",
       "40  _eou_ <sos> >>P: Yes, he is. Yeah.  _eou_ <sos...   \n",
       "41  _eou_ <sos> >>T: Alrigh. No pun intended, righ...   \n",
       "42  <sos> >>T: Hi Sandra. How are you doing today....   \n",
       "43  _eou_ <sos> >>T: are you going to? _eou_ <sos>...   \n",
       "44  _eou_ <sos> >>P: Yeah _eou_ <sos> >>T: okay. O...   \n",
       "45  _eou_ <sos> >>T: And you're having what sounds...   \n",
       "46  _eou_ <sos> >>T: So that was one issue. Now if...   \n",
       "47  _eou_ <sos> >>P: Okay,  _eou_ <sos> >>T: so le...   \n",
       "48  _eou_ <sos> >>P: Sure, my left elbow is actual...   \n",
       "\n",
       "                                            Generated  \\\n",
       "0    in your life that you can talk to. What do yo...   \n",
       "1     >>T: Hello, Peggy, how you doing today? _eou...   \n",
       "2    change and it's very important to you that yo...   \n",
       "3     >>T: Jasmine how you doing today? _eou_  >>P...   \n",
       "4    versus just not just a friend's house like an...   \n",
       "5    back. _eou_  >>T: So you weren't you weren't ...   \n",
       "6    went anyway. _eou_  >>T: So was it after he h...   \n",
       "7    late, but I'm late enough. _eou_  >>T: Have y...   \n",
       "8    >>T: But eventually you're going to come to o...   \n",
       "9    around. _eou_  >>T: So mainly just kind of ha...   \n",
       "10   hallway? _eou_  >>P: Just different things. _...   \n",
       "11   I can see how distressed This makes you feel....   \n",
       "12   dad is Steve. They actually got divorced when...   \n",
       "13   I don't like I feel back. It might be hard, l...   \n",
       "14   No, I mean, I don't want my son, If he ever f...   \n",
       "15   if this had happened to. Have you ever been i...   \n",
       "16   like that. _eou_  >>T: And when you and your ...   \n",
       "17   She's upset about that. _eou_  >>P: Yeah, yea...   \n",
       "18   I just did it myself, _eou_  >>T: does it fru...   \n",
       "19   want to hurt anyone. I feel like I've got to ...   \n",
       "20   you want to discuss? Or I mean, would you lik...   \n",
       "21   I'm wondering if part of the difficulty you'r...   \n",
       "22   same time when those thoughts come up to resp...   \n",
       "23   when I try and sleep I just can't seem to hav...   \n",
       "24   nervous on edge, anything? _eou_  >>P: Well, ...   \n",
       "25   be able to take care of them, even if you're ...   \n",
       "26    >>T: Jasmine how you doing today?  _eou_  An...   \n",
       "27   the doctor that you're going to see. Let's ju...   \n",
       "28   _eou_  >>T: Okay, so would it work if I was m...   \n",
       "29   the service of _eou_  >>P: the Advanced Study...   \n",
       "30   don't know. I don't know if there is what was...   \n",
       "31   got it all that felt so good get it up so the...   \n",
       "32   and they end up leaving anyway. _eou_  >>T: R...   \n",
       "33   Okay, _eou_  >>P: yes. _eou_  >>T: And. Okay,...   \n",
       "34   you easily distracted? _eou_  >>P: Yes. Take ...   \n",
       "35   But some of those were half days. They add up...   \n",
       "36   you're reacting to the quizzes maybe. _eou_  ...   \n",
       "37   contributing to the way that he's behaving to...   \n",
       "38   maybe to 16 when you were more active. involv...   \n",
       "39   _eou_  >>T: Okay. Okay, but you've not wanted...   \n",
       "40   ultimately a judge can order me and I have to...   \n",
       "41   through a possible scenario. And what this co...   \n",
       "42   >>P: I am 20. _eou_  >>T: You're 20 Okay, whe...   \n",
       "43   Yes. Safety. Definitely my personal safety or...   \n",
       "44   _eou_  >>P: Yeah. drugs, alcohol. Yeah, I'd r...   \n",
       "45    >>T: Um, is there anything else? _eou_  >>P:...   \n",
       "46   good enough and on the other way and it's not...   \n",
       "47   encounter, and that's where you're getting th...   \n",
       "48   _eou_  >>P: Yeah, just this feeling of failur...   \n",
       "\n",
       "                                               Target  dac_next  predicted_rac  \n",
       "0   And I think also, he understood why I did it. ...         3              3  \n",
       "1   I don't really feel like filling out a plan. I...         5              5  \n",
       "2   Okay. And we'll talk about any type of legal p...         0              3  \n",
       "3                                               Yeah.         6              1  \n",
       "4   Um, you know, I want to make sure that all the...         1              5  \n",
       "5   How would you describe your mood? Most of the ...         0              6  \n",
       "6   And you believe them now. Right? So try to kee...         6              5  \n",
       "7                           No, I just stopped going         10              5  \n",
       "8   And then I'm Facebook friends when they go hom...         1              5  \n",
       "9                    What are you gonna do if I fail?         3              6  \n",
       "10                                               Yes.         6              1  \n",
       "11  long time ago, I've been using proudly for Sin...         0              5  \n",
       "12                                              Okay.         5              0  \n",
       "13  And how many days and the average week are you...         8              6  \n",
       "14  Yeah. You know, like, sometimes people just, i...         6              3  \n",
       "15  Well, actually, for this semester, I already t...         1              5  \n",
       "16                              Being able to travel.         3              3  \n",
       "17  Have you noticed a change in your ability to e...         5              6  \n",
       "18  you have some social problems. Not so much wit...         3              3  \n",
       "19                                              Okay.         8              0  \n",
       "20                             I'd hope he'd say yes.         5              1  \n",
       "21  Okay, so it sounds like you're saying then it'...         1              3  \n",
       "22  So I like that adaptive response. Right. Do yo...         1              3  \n",
       "23  So what do you think the solution here is your...         7              6  \n",
       "24  Okay, well, perhaps it would be helpful to sor...         6              5  \n",
       "25                          Wow, I would say probably         6              5  \n",
       "26  Not like this. Now is the first time I've just...         5              5  \n",
       "27                       so tell me how it helps you.         5              6  \n",
       "28                                 Yeah, I think yes.         2              1  \n",
       "29  Correct. Without my room, and without the tech...         0              3  \n",
       "30                        Um, is there anything else?         5              2  \n",
       "31  Oh, so you are on the water pill? The furosemi...         5              3  \n",
       "32  your physicians, physicians run tests for all ...         6              3  \n",
       "33  Um, I mean, I have I've had a few boyfriends b...         7              5  \n",
       "34  A lot of the corsage to some of the effectiven...        10              5  \n",
       "35                                Yeah. In situation.         4              1  \n",
       "36  Yeah. Oh, It has crept up over the years. Well...         5              5  \n",
       "37                       right. So is it mainly vodka         3              3  \n",
       "38  So Victor, tell me, how's your sleep? And what...         6              6  \n",
       "39  Yeah, maybe I just need to let him know that A...         4              5  \n",
       "40  Well, it's the same thing that I see Dr. Jones...         3              5  \n",
       "41  And we want you to be able to, you know, genui...         1              3  \n",
       "42  I'm going to ask you some questions and give y...         0              3  \n",
       "43                                    Before for bed?         2              3  \n",
       "44  yes, And at the same time, I had a barium enem...         7              5  \n",
       "45  you are. So no one's really seeing you have th...         1              3  \n",
       "46                             okay hundred percent ?         2              3  \n",
       "47                                           Oh yeah,         6              1  \n",
       "48  Um, it's just kind of a throbbing pain, it'll ...         1              5  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fbf062-ba84-4e0c-808f-e41d3da73a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # \"lm_name\": \"/content/drive/MyDrive/MWP_gpt2_paraphrases_512\",\n",
    "    # \"ref_lm_name\": \"/content/drive/MyDrive/MWP_gpt2_paraphrases_512\",\n",
    "    # \"cls_model_name\": \"/content/drive/MyDrive/question_paraphrasing_semantic_similarity_models/ParaQD_v3.1\",\n",
    "    \"tk_name\": \"gpt2\",\n",
    "    \"steps\": 51200,\n",
    "    \"batch_size\": 18,\n",
    "    \"forward_batch_size\": 9,\n",
    "    \"ppo_epochs\": 5,   \n",
    "    \"txt_in_len\": 15,\n",
    "    \"txt_out_len\": 50,\n",
    "    \"lr\": 1.41e-4,\n",
    "    \"init_kl_coef\":0.2,\n",
    "    \"target\": 6,\n",
    "    \"horizon\":10000,\n",
    "    \"gamma\":1,\n",
    "    \"lam\":0.95,\n",
    "    \"cliprange\": .2,\n",
    "    \"cliprange_value\":.2,\n",
    "    \"vf_coef\":.1, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba3288-5b68-46a4-ae48-3a0032c6397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = gpt2_model.to(device)\n",
    "_ = gpt2_model_ref.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27659c-fcf0-4fa5-8e73-42be37c24bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rouge-metric\n",
    "bhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dff5c3-b53c-45b8-937f-21199cda6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import evaluate \n",
    "# import rouge\n",
    "nltk.download('punkt')\n",
    "\n",
    "# model_sentence = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def get_diversity(actual, generated):\n",
    "    generated = generated.split(\" \")\n",
    "    actual = actual.split(\" \")\n",
    "    # rouge = evaluate.load('rouge')\n",
    "    # results_r = rouge.compute(predictions=[sentence1],\n",
    "    #                      references=[sentence2])\n",
    "    \n",
    "    \n",
    "    results = nltk.translate.bleu_score.sentence_bleu([actual], generated, weights = [1]) \n",
    "    return results\n",
    "\n",
    "def get_reward(sentence_1, sentence_2):\n",
    "    lambda1 = 1\n",
    "    # semantic_preservation = score_biencoder(model, sentence_1, sentence_2)\n",
    "    sentences = [sentence_1, sentence_2]\n",
    "    # paraphrase_score = util.paraphrase_mining(model, sentences)[0][0]\n",
    "    \n",
    "    print(\"Gnerated: \", sentence_1)\n",
    "    print(\"Target: \", sentence_2)\n",
    "    diversity = get_diversity(sentence_2, sentence_1)\n",
    "    # print(lambda1 * diversityget_re\n",
    "    print(lambda1 * (diversity + paraphrase_score))\n",
    "    return lambda1 * (diversity + paraphrase_score)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939aa22-1ab7-4da0-92d1-18105ec3b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ec2de-dc85-4895-9d37-352c85b60480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"query\"] = df.Utterance\n",
    "df3 = pd.read_csv(\"train.csv\")\n",
    "\n",
    "df[\"target\"] = [str(x) for x in df3[\"Utterance\"][1:]]\n",
    "labels = [int(x) for x in df[\"Dialogue_Act\"][1:]]\n",
    "labels.append(0)\n",
    "\n",
    "df[\"dac_labels\"] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e94cfd-493f-4a4f-b524-03ec3271d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = [torch.tensor(gpt2_tokenizer.encode_plus(str(x), \\\n",
    "                max_length=300, pad_to_max_length=True, add_special_tokens=True, truncation = True, return_attention_mask=True)[\"input_ids\"]\n",
    ") for x in df[\"Utterance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ec6c062a-66c7-46b8-9e3a-7b4ec00caba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 11 17:10:24 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  RTX A6000           On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 39%   69C    P2    96W / 300W |  14267MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  RTX A6000           On   | 00000000:61:00.0 Off |                  Off |\n",
      "| 31%   60C    P8    32W / 300W |   2592MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   2837206      C   ...da3/envs/myenv/bin/python     2073MiB |\n",
      "|    0   N/A  N/A   3297455      C   python3                         12191MiB |\n",
      "|    1   N/A  N/A   3297455      C   python3                          2589MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d942d38-7836-4594-b7b7-3f1bb939acf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd14ccc-5946-468a-8809-ae595b905c00",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # import \n",
    "# gen_kwargs = {\n",
    "#     \"min_length\":20,\n",
    "#     \"top_k\": 8,\n",
    "#     \"top_p\": 0.9,\n",
    "#     \"do_sample\": True,\n",
    "#     \"pad_token_id\": gpt2_tokenizer.pad_token_id\n",
    "# }\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# import re\n",
    "# # from quantulum3 import parser\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# # import requests\n",
    "# # import json\n",
    "# # from nltk.corpus import wordnet\n",
    "# # from nltk.tokenize import word_tokenize\n",
    "# # import nltk\n",
    "# # nltk.download('wordnet')\n",
    "# # nltk.download('punkt')\n",
    "# # import inflect\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# # from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
    "# import torch\n",
    "# import logging\n",
    "# # from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import random\n",
    "# import pickle\n",
    "# from scipy.spatial.distance import cdist\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ppo_trainer = PPOTrainer(gpt2_model, gpt2_model_ref, gpt2_tokenizer,  **config)\n",
    "# fbs = config['forward_batch_size']\n",
    "# gen_len = 15\n",
    "# for epoch in tqdm(range(int(np.ceil(config[\"steps\"]/config['batch_size'])))):\n",
    "#     # torch.cuda.empty_cache()\n",
    "#     logs = dict()\n",
    "#     game_data = dict()\n",
    "#     timing = dict()\n",
    "#     t0 = time.time()\n",
    "    \n",
    "#     #### get a batch from the dataset\n",
    "#     df_batch = df.sample(config['batch_size'])\n",
    "#     game_data['query'] = df_batch['query'].tolist()\n",
    "#     game_data[\"target\"] = df_batch[\"target\"].tolist()\n",
    "#     # tens = torch.tensor(df_batch['tokens'].tolist()).to(device\n",
    "#     tens = []\n",
    "#     for i in df_batch['tokens']:\n",
    "#         tens.append(torch.tensor(i).to(device))\n",
    "#     # query_tensors = torch.stack(df_batch['tokens'].tolist())\n",
    "#     query_tensors = torch.stack(tens)\n",
    "#     dac_labels = torch.tensor(df_batch[\"dac_labels\"].tolist()).to(device)\n",
    "#     #### get response from gpt2\n",
    "#     t = time.time()\n",
    "#     total_length = config['txt_in_len']+config['txt_out_len']\n",
    "#     response_tensors = []\n",
    "#     for i in range(int(config['batch_size']/fbs)):\n",
    "#         response  = respond_to_batch(gpt2_model, query_tensors[i*fbs:(i+1)*fbs],\n",
    "#                                      txt_len= 50, top_k = 8)\n",
    "#         response_tensors.append(response)\n",
    "#         # for j in range(i*fbs,(i+1)*fbs):\n",
    "#         # response = gpt2_model.generate(query_tensors[i*fbs:(i+1)*fbs], \n",
    "#         #                                max_new_tokens=gen_len, **gen_kwargs, size_penalty = -10)\n",
    "#         # response_tensors.append(response.squeeze()[-gen_len:])\n",
    "#         # response_tensors.append(response)\n",
    "#     response_tensors = torch.cat(response_tensors).to(device)\n",
    "#     game_data['response'] = [gpt2_tokenizer.decode(response_tensors[i, :],  skip_special_tokens=True) for i in range(config['batch_size'])]\n",
    "#     timing['time/get_response'] = time.time()-t\n",
    "\n",
    "#     #### tokenize text for sentiment analysis\n",
    "#     t = time.time()\n",
    "#     # texts = [q + r for q,r in zip(game_data['query'], game_data['response'])]\n",
    "\n",
    "#     # sentiment_inputs, attention_masks = build_bert_batch_from_txt(texts, sentiment_tokenizer, device)    \n",
    "#     timing['time/build_input_sentiment'] = time.time()-t\n",
    "\n",
    "#     #### get sentiment score\n",
    "#     t = time.time()\n",
    "#     rewards = []\n",
    "#     for i in range(int(config['batch_size']/fbs)):\n",
    "#         # res = sentiment_model.forward(sentiment_inputs[i*fbs:(i+1)*fbs],\n",
    "#         #                               attention_masks[i*fbs:(i+1)*fbs])[0][:, 1].detach()\n",
    "#         for sentence1, sentence2 in zip(game_data['response'][i*fbs:(i+1)*fbs],game_data['target'][i*fbs:(i+1)*fbs]):\n",
    "#             res = get_reward(model_sentence, sentence1,sentence2)\n",
    "#             rewards.append(torch.tensor([res]))\n",
    "#     rewards = torch.cat(rewards).to(device)\n",
    "#     timing['time/get_sentiment_preds'] = time.time()-t\n",
    "    \n",
    "#     #### Run PPO training \n",
    "#     t = time.time()\n",
    "#     stats = ppo_trainer.step(query_tensors, response_tensors, rewards, dac_labels)\n",
    "#     timing['time/optimization'] = time.time()-t\n",
    "     \n",
    "#     #### Log everything\n",
    "#     timing['time/epoch'] = time.time()-t0\n",
    "#     table_rows = [list(r) for r in zip(game_data['query'], game_data['response'], rewards.cpu().tolist())]\n",
    "#     logs.update({'game_log':wandb.Table(\n",
    "#         columns=['query', 'response', 'reward'],\n",
    "#         rows=table_rows)})\n",
    "#     logs.update(timing)\n",
    "#     logs.update(stats)\n",
    "#     logs['env/reward_mean'] = torch.mean(rewards).cpu().numpy()\n",
    "#     logs['env/reward_std'] = torch.std(rewards).cpu().numpy()\n",
    "#     logs['env/reward_dist'] = rewards.cpu().numpy()\n",
    "#     torch.save(gpt2_model.state_dict(), \"model_trained_checkpoint1.pt\")\n",
    "#     # print(logs)\n",
    "#     wandb.log(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac54a05-de2b-4537-ac36-71397b549277",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edited.Utterance[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed46a00-915f-4792-ab01-3febe7f7807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_loss:  tensor(0.7857, device='cuda:1', grad_fn=<AddBackward0>)\n",
    "# LM_Loss:  tensor(0.6318, device='cuda:1', grad_fn=<NllLossBackward0>) \n",
    "# Loss_p:  tensor(0.1523, device='cuda:1', grad_fn=<MeanBackward0>) \n",
    "# Loss_v:  tensor(16.0353, device='cuda:1', grad_fn=<MulBackward0>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d4fff-3a95-4dce-babd-d54593046183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26eac38-a70d-4bce-b463-f04a1d5f8146",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gpt2_model.state_dict(), \"model_trained1.pt\")\n",
    "# gpt2_model.load_state_dict(torch.load(\"model_trained.pt\")) \n",
    "# gpt2_model_ref "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f780f2ea-a497-420a-a465-a6e3463c5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### get a batch from the dataset\n",
    "bs = 2\n",
    "game_data = dict()\n",
    "df_batch = df.sample(bs)\n",
    "game_data['query'] = df_batch['query'].tolist()\n",
    "query_tensors = torch.stack(df_batch['tokens'].tolist()).to(device)\n",
    "\n",
    "#### get response from gpt2 and gpt2_ref\n",
    "total_length = config['txt_in_len']+config['txt_out_len']\n",
    "response_tensors_ref  = respond_to_batch(gpt2_model, query_tensors, None, 10)\n",
    "game_data['Response'] = [gpt2_tokenizer.decode(response_tensors_ref[i, :], skip_special_tokens = True) for i in range(bs)]\n",
    "\n",
    "response_tensors  = gpt2_model_ref.generate(query_tensors)\n",
    "game_data[\"Targets\"]= df_batch[\"target\"]\n",
    "game_data['response (after)'] = [gpt2_tokenizer.decode(response_tensors[i, :], skip_special_tokens = True) for i in range(bs)]\n",
    "\n",
    "#### sentiment analysis of query/response pairs before/after\n",
    "# texts = [q + r for q,r in zip(game_data['query'], game_data['response (before)'])]\n",
    "# sentiment_inputs, attention_masks = build_bert_batch_from_txt(texts, sentiment_tokenizer, device)    \n",
    "# rewards = sentiment_model.forward(sentiment_inputs, attention_masks)[0][:, 1].detach()\n",
    "# game_data['rewards (before)'] = rewards.cpu().numpy()\n",
    "\n",
    "# texts = [q + r for q,r in zip(game_data['query'], game_data['response (after)'])]\n",
    "# sentiment_inputs, attention_masks = build_bert_batch_from_txt(texts, sentiment_tokenizer, device)    \n",
    "# rewards = sentiment_model.forward(sentiment_inputs, attention_masks)[0][:, 1].detach()\n",
    "# game_data['rewards (after)'] = rewards.cpu().numpy()\n",
    "# DacHead\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(game_data)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d85e75-cd01-40d9-8d7a-71714bd4ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a40c7-38ff-4827-86b4-fb79738f7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
